{"cells":[{"cell_type":"code","execution_count":null,"id":"f5a097b3-0e7a-424e-8e5b-f5b99f577e0d","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["%pip install opencv-python imutils"]},{"cell_type":"code","execution_count":null,"id":"f09be3b2-4703-49cb-a1f2-64e73f5c2b18","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["import multiprocessing\n","\n","num_cores = multiprocessing.cpu_count()\n","print(\"Number of available cores:\", num_cores)"]},{"cell_type":"markdown","id":"a659df9b-acb4-462b-818c-46dde1b74a92","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["Define a function tat takes a pandas dataframe and since there are diffrent seasons in the training set and diffrent number of images per season and different images per season. By looking at the first few chracters of the seq_id we can know which season an image belongs to. \n","\n","This function takes a single argument `df`, which is the pandas DataFrame containing the `seq_id` column. The function first extracts the season from the `seq_id` column using a lambda function, and then counts the number of sequences in each season using the `value_counts` method of the pandas Series object. The counts are sorted by season using the `sort_index` method.\n","\n","The function then replaces the `'SER_'` prefix in the season labels with an empty string for easy visibility, and creates a bar plot using `plt.bar`. The x-axis represents the season labels and the y-axis represents the number of sequences in each season. Finally, the function displays the plot using `plt.show`.\n","\n","You can call this function with your DataFrame `df_train` to plot the number of sequences in each season. For example, you can call `plot_season_counts(df_train)` to plot the season counts."]},{"cell_type":"code","execution_count":null,"id":"5e3245c2-1faf-4929-80ac-fdf147b9122e","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","def plot_season_counts(df, title=\"Number of Sequences per Season\"):\n","    # Extract the season from the seq_id column using a lambda function\n","    df['season'] = df.seq_id.map(lambda x: x.split('#')[0])\n","\n","    # Count the number of sequences in each season, and sort the counts by season\n","    season_counts = df.season.value_counts().sort_index()\n","\n","    # Replace 'SER_' prefix in season labels with an empty string for easy visibility\n","    season_labels = [s.replace('SER_', '') for s in season_counts.index]\n","\n","    # Create a bar plot where the x-axis represents the season and the y-axis represents the number of sequences in that season\n","    sns.barplot(x=season_labels, y=season_counts.values)\n","    plt.xlabel('Season')\n","    plt.ylabel('Number of sequences')\n","    plt.title(title)\n","    plt.show()"]},{"cell_type":"markdown","id":"21deeac5-4eb4-45f2-801d-102fccd87a8a","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["**Load Data**\n","\n","Read the annotations data from the lakehouse which forms our traininng set. from this we get information about each season's sequences and labels uisng this data which provided linka between the image_ids and sequences as well as what category is ins a given sequence.\n","\n","We filter out the relevant columns we'll need , *i.e season, seq_id, category_id, image_id and date_time*. We also need to filter out all records whose category_id is greater than 1 to exclue all empty and huma images which are not relevant for tgis training. \n","\n","We also remove any null values in the image_id column and drop any duplicate lrows, finally convert the spark df to a pandas dataframe for easier manipulation.\n"]},{"cell_type":"code","execution_count":null,"id":"5e9febed-7d83-4f05-87e8-27b074449696","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Read all the annotations in the train table from the lakehouse\n","df = spark.sql(\"SELECT * FROM DemoLakehouse.train_annotations WHERE train_annotations.category_id > 1\")\n","\n","# filter out the season, sequence ID, category_id snf image_id\n","df_train = df.select(\"season\", \"seq_id\", \"category_id\", \"location\", \"image_id\", \"datetime\")\n","\n","# remove image_id wiTH null and duplicates\n","df_train = df_train.filter(df_train.image_id.isNotNull()).dropDuplicates()\n","\n","# convert df_train to pandas dataframe\n","df_train = df_train.toPandas()"]},{"cell_type":"markdown","id":"77fa7118-f22c-4df1-93e3-9da0ea69d360","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["We can visualize the number of images we have for each sequence and as below by far most sequesnces have between 1 and 3 images in them"]},{"cell_type":"code","execution_count":null,"id":"bdc3b9c8-b535-438a-a9b7-5563a71f884a","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Create the count plot\n","ax = sns.countplot(x=df_train.groupby('seq_id').size(), log=True)\n","\n","# Set the title and axis labels\n","ax.set_title('Number of images in each sequence')\n","ax.set_xlabel('Number of images')\n","ax.set_ylabel('Count of sequences')\n","\n","# Show the plot\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","id":"93430c5f-794b-48a6-830c-9a58e1675929","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["Load the category names from the Categories table in the lakehouse. We'll then convert the spark dataframe to a pandas dataframe. Next the add a new\n","column called *label* in the df_train dataframe which is the category name for each category_id. Then remove the category_id column from df_train.\n","\n","Also rename the image_id column to filename and append the .JPG extension to the the values"]},{"cell_type":"code","execution_count":null,"id":"7ed02c3b-c3ef-4867-b62a-4267dc9315db","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["import numpy as np\n","\n","# Load the Categories DataFrame into a pandas DataFrame\n","category_df = spark.sql(\"SELECT * FROM DemoLakehouse.categories\").toPandas()\n","\n","# Map category IDs to category names using a vectorized approach\n","category_map = pd.Series(category_df.name.values, index=category_df.id)\n","df_train['label'] = category_map[df_train.category_id].values\n","\n","# Drop the category_id column\n","df_train = df_train.drop('category_id', axis=1)\n","\n","# Rename the image_id column to filename\n","df_train = df_train.rename(columns={'image_id': 'filename'})\n","\n","# Append the .JPG extension to the filename column\n","df_train['filename'] = df_train.filename + '.JPG'"]},{"cell_type":"markdown","id":"8bbd79cb-f4f4-4c5d-9ed1-56f43134794c","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["We'll then pick the first image from each sequence, the assumption is that the time period after a camera trap is triggered is the most likely time for an animal to be in the frame."]},{"cell_type":"code","execution_count":null,"id":"f8ea33bc-7818-4f40-a906-17c2e8283576","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# reduce to first frame only for all sequences\n","df_train = df_train.sort_values('filename').groupby('seq_id').first().reset_index()\n","\n","df_train.count()"]},{"cell_type":"markdown","id":"000360d5-9048-41e2-8d0a-59967159daf9","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["The plot shows the distribution of the labels, where each bar represents the number of images with that label. The y-axis label is set to \"Label\", and the x-axis label is set to \"Number of images\". The horizontal orientation of the bars, the increased figure size, the added spacing between the labels, and the logarithmic scale of the x-axis make it easier to read the labels and normalize the distribution."]},{"cell_type":"code","execution_count":null,"id":"44617406-59e2-4963-959b-2023da838bb2","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Create a horizontal bar plot where the y-axis represents the label and the x-axis represents the number of images with that label\n","plt.figure(figsize=(8, 12))\n","sns.countplot(y='label', data=df, order=df_train['label'].value_counts().index)\n","plt.xlabel('Number of images')\n","plt.ylabel('Label')\n","\n","# Set the x-axis scale to logarithmic\n","plt.xscale('log')\n","\n","plt.show()"]},{"cell_type":"markdown","id":"73f16ba4-af51-4108-b45c-288408553331","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["Using the file name from the datafram use the defined function that takes the filename as input and returm the url to the image. The function is then applied to the `filename` column of a pandas DataFrame `df_train` to create a new column `image_url` containing the URLs for each image."]},{"cell_type":"code","execution_count":null,"id":"b85b86b9-76e9-4f4e-8520-aa91421c98a1","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Define a function to apply to the filename column\n","def get_ImageUrl(filename):\n","    return f\"https://lilablobssc.blob.core.windows.net/snapshotserengeti-unzipped/{filename}\"\n","\n","# Create a new column in the dataframe using the apply method\n","df_train['image_url'] = df_train['filename'].apply(get_ImageUrl)\n"]},{"cell_type":"markdown","id":"7616d5cd-643a-4039-9bf8-83031f72a177","metadata":{"nteract":{"transient":{"deleting":false}}},"source":[]},{"cell_type":"code","execution_count":null,"id":"82a178c6-07a7-4242-9f67-7d3fd535bb20","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["import urllib.request\n","\n","def display_random_image(label, random_state, width=500):\n","    # Filter the DataFrame to only include rows with the specified label\n","    df_filtered = df_train[df_train['label'] == label]\n","    \n","    # Select a random row from the filtered DataFrame\n","    row = df_filtered.sample(random_state=random_state).iloc[0]\n","    \n","    # Load the image from the URL and display it\n","    url = row['image_url']\n","    download_and_display_image(url, label)\n","\n","def download_and_display_image(url, label):\n","    image = plt.imread(urllib.request.urlopen(url), format='jpg')\n","    plt.imshow(image)\n","    plt.title(f\"Label: {label}\")\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"id":"3477f501-8739-440b-b254-12ca982f42d8","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["display_random_image(label='leopard', random_state=12)"]},{"cell_type":"code","execution_count":null,"id":"65616bf0-587b-447d-afb6-1740b9726e78","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["def proportional_allocation_percentage(data, percentage):\n","    # Calculate the count of the original sample\n","    original_count = len(data)\n","\n","    # Calculate the count of the sample based on the percentage\n","    sample_count = int((percentage / 100) * original_count)\n","\n","    # Perform proportional allocation on the calculated sample count\n","    return proportional_allocation(data, sample_count)"]},{"cell_type":"code","execution_count":null,"id":"b37fb461-2e6b-47de-a3fd-e801a243e53f","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["def proportional_allocation(data, sample_size):\n","    # Group the data by \"label\", \"season\", and \"location\" columns\n","    grouped_data = data.groupby([\"label\", \"season\", \"location\"])\n","\n","    # Calculate the proportion of each group in the original sample\n","    proportions = grouped_data.size() / len(data)\n","\n","    # Calculate the count of each group in the sample based on proportions\n","    sample_sizes = np.round(proportions * sample_size).astype(int)\n","\n","    # Calculate the difference between the desired sample size and the sum of rounded sample sizes\n","    size_difference = sample_size - sample_sizes.sum()\n","\n","    # Adjust the sample sizes to account for the difference\n","    if size_difference > 0:\n","        # If there is a shortage of items, allocate the additional items to the groups with the largest proportions\n","        largest_proportions = proportions.nlargest(size_difference)\n","        for group in largest_proportions.index:\n","            sample_sizes[group] += 1\n","    elif size_difference < 0:\n","        # If there is an excess of items, reduce the sample sizes from the groups with the smallest proportions\n","        smallest_proportions = proportions.nsmallest(-size_difference)\n","        for group in smallest_proportions.index:\n","            sample_sizes[group] -= 1\n","\n","    # Initialize an empty list to store the sample\n","    sample_data = []\n","\n","    # Iterate over each group and randomly sample the required count\n","    for group, count in zip(grouped_data.groups, sample_sizes):\n","        indices = grouped_data.groups[group]\n","        sample_indices = np.random.choice(indices, size=count, replace=False)\n","        sample_data.append(data.loc[sample_indices])\n","\n","    # Concatenate the sampled dataframes into a single dataframe\n","    sample_data = pd.concat(sample_data)\n","\n","    # Reset the index of the sample DataFrame\n","    sample_data.reset_index(drop=True, inplace=True)\n","\n","    return sample_data"]},{"cell_type":"code","execution_count":null,"id":"8c7c9454-2bf7-422a-a575-eec88b144536","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["percent = 0.05\n","sampled_train = proportional_allocation_percentage(df_train, percent)\n","plot_season_counts(sampled_train, f\"{percent}% Sample from Original Number of Sequences per Season\")"]},{"cell_type":"code","execution_count":null,"id":"d67aed14","metadata":{},"outputs":[],"source":["import urllib.request\n","import cv2\n","import imutils\n","\n","def download_and_resize_image(url, path, kind):\n","    filename = os.path.basename(path)\n","    directory = os.path.dirname(path)\n","\n","    directory_path = f'/lakehouse/default/Files/images/{kind}/{directory}/'\n","\n","    # Create the directory if it does not exist\n","    os.makedirs(directory_path, exist_ok=True)\n","\n","    # check if file already exists\n","    if os.path.isfile(os.path.join(directory_path, filename)):\n","        return\n","\n","    # Download the image\n","    urllib.request.urlretrieve(url, filename)\n","\n","    # Read the image using OpenCV\n","    img = cv2.imread(filename)\n","\n","    # Resize the image to a reasonable ML training size using imutils\n","    resized_img = imutils.resize(img, width=224, height=224, inter=cv2.INTER_AREA)\n","\n","    # Save the resized image to a defined filepath\n","    cv2.imwrite(os.path.join(directory_path, filename), resized_img)"]},{"cell_type":"code","execution_count":null,"id":"ae502e79","metadata":{},"outputs":[],"source":["import concurrent.futures\n","\n","def execute_parallel_download(df, kind):\n","    # Use a process pool instead of a thread pool to avoid thread safety issues\n","    with concurrent.futures.ProcessPoolExecutor() as executor:\n","        # Batch process images instead of processing them one at a time\n","        urls = df['image_url'].tolist()\n","        paths = df['filename'].tolist()\n","        futures = [executor.submit(download_and_resize_image, url, path, kind) for url, path in zip(urls, paths)]\n","        # Wait for all tasks to complete\n","        concurrent.futures.wait(futures)"]},{"cell_type":"code","execution_count":null,"id":"35ab2975","metadata":{},"outputs":[],"source":["df = spark.sql(\"SELECT * FROM DemoLakehouse.test_annotations WHERE test_annotations.category_id > 1\")\n","\n","df_test = df.select(\"season\", \"seq_id\", \"category_id\", \"location\", \"image_id\", \"datetime\")\n","\n","df_test= df_test.filter(df_test.image_id.isNotNull()).dropDuplicates()\n","\n","df_test = df_test.toPandas()\n","\n","df_test['label'] = category_map[df_test.category_id].values\n","\n","df_test = df_test.drop('category_id', axis=1)\n","\n","df_test = df_test.rename(columns={'image_id':'filename'})\n","\n","df_test['filename'] = df_test.filename+ '.JPG'\n","\n","df_test = df_test.sort_values('filename').groupby('seq_id').first().reset_index()\n","\n","df_test['image_url'] = df_test['filename'].apply(get_ImageUrl)\n","\n","sampled_test = proportional_allocation_percentage(df_test, 0.27)"]},{"cell_type":"code","execution_count":null,"id":"e3ed3da2","metadata":{},"outputs":[],"source":["import os\n","\n","execute_parallel_download(sampled_train, 'train')\n","execute_parallel_download(sampled_test, 'test')\n"]},{"cell_type":"code","execution_count":null,"id":"0d11447a","metadata":{},"outputs":[],"source":["data_dir = '/lakehouse/default/Files/data/'\n","\n","train_data_file = os.path.join(data_dir, 'sampled_train.parquet')\n","test_data_file = os.path.join(data_dir, 'sampled_test.parquet')\n","\n","sampled_train.loc[:, ['filename', 'label']].to_parquet(train_data_file, engine='pyarrow', compression='snappy')\n","sampled_test.loc[:, ['filename', 'label']].to_parquet(test_data_file, engine='pyarrow', compression='snappy')\n"]}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.9"},"notebook_environment":{},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{},"enableDebugMode":false}},"synapse_widget":{"state":{},"version":"0.1"},"trident":{"lakehouse":{"default_lakehouse":"5f58e739-d87b-404a-9a7b-5e64738a82c5","default_lakehouse_name":"Serengeti_Lakehouse","default_lakehouse_workspace_id":"1eaa972c-c94a-47fa-90f5-bcad0a19f945","known_lakehouses":[{"id":"5f58e739-d87b-404a-9a7b-5e64738a82c5"}]}},"widgets":{}},"nbformat":4,"nbformat_minor":5}
